{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducing results gradient interpolation WOT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-top: 20px; margin-bottom: 20px; text-align: center;\">\n",
    "    <img src=\"images/gradient.png\" alt=\"Image description\" style=\"max-width: 50%; height: auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before running the notebook, ensure you have ran the following commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You have trained the VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```jsx\n",
    "echo \"Training Autoencoder, this might take a long time\"\n",
    "CUDA_VISIBLE_DEVICES=0 python /path/to/VAE_train.py --data_dir '/path/where/you/saved/data/WOT/filted_data.h5ad' --num_genes 19423 --state_dict '/path/to/pretrained/VAE/annotation_model_v1' --save_dir '/dir/where/to/save/the/VAE/model' --max_steps 50000 --max_minutes 300\n",
    "echo \"Training Autoencoder done\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to do the following change on top of **VAE_train.py** to specify we are loading WOT data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# from guided_diffusion.cell_datasets import load_data\n",
    "# from guided_diffusion.cell_datasets_sapiens import load_data\n",
    "from guided_diffusion.cell_datasets_WOT import load_data\n",
    "# from guided_diffusion.cell_datasets_muris import load_data\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the data-loading function the original dataset is filtered to take out data points D3.5 and D4 for training the VAE. The VAE converges very fast: 50'000 steps are more than enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You have trained the diffusion model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```jsx\n",
    "echo \"Training diffusion backbone\"\n",
    "CUDA_VISIBLE_DEVICES=0 python /path/to/cell_train.py --data_dir '/path/where/you/saved/data/WOT/filted_data.h5ad'  --vae_path '/path/where/you/saved/VAE/model.pt' \\\n",
    " --save_dir '/dir/where/to/save/the/diffusion/model' --model_name 'choose_any_name' --lr_anneal_steps 80000\n",
    "echo \"Training diffusion backbone done\" \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where we changed at the top of cell_train.py the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# from guided_diffusion.cell_datasets import load_data\n",
    "from guided_diffusion.cell_datasets_WOT import load_data\n",
    "# from guided_diffusion.cell_datasets_sapiens import load_data\n",
    "# from guided_diffusion.cell_datasets_muris import load_data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model converges relatively fast, anything above 50000 steps should be vastly sufficient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You have trained the classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```jsx\n",
    "echo \"Training diffusion backbone\"\n",
    "CUDA_VISIBLE_DEVICES=0 python /path/to/cell_train.py --data_dir '/path/where/you/saved/data/WOT/filted_data.h5ad' --model_path '/dir/where/to/save/the/diffusion/model'  \\\n",
    "  --iterations 100000 --vae_path '/path/where/you/saved/VAE/model.pt' \n",
    "echo \"Training diffusion backbone done\" \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where we changed the top of **classifier_train.py** as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# from guided_diffusion.cell_datasets import load_data\n",
    "from guided_diffusion.cell_datasets_WOT import load_data\n",
    "# from guided_diffusion.cell_datasets_sapiens import load_data\n",
    "# from guided_diffusion.cell_datasets_muris import load_data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also ensure that the default number of classes is set to 15 line 235:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# In classifier_train.py line 235 ensure:\n",
    "defaults['num_class']= 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating latent spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In classifier_sample.py, we need to change the following lines:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#line 319 of classifier_sample.py\n",
    "defaults['num_class'] = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the main function as: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    # for Gradient Interpolation, run\n",
    "    parser = create_argparser()\n",
    "    args = parser.parse_args()\n",
    "    save_dir = args.sample_dir\n",
    "    for i in range(0,11):\n",
    "        path_to_save = save_dir + f\"{i}\"\n",
    "        to_save = main(cell_type=[6,7], inter=True, weight=[10-i,i])\n",
    "        save_data(to_save, i, path_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can then run the following command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```jsx\n",
    "# Conditional sampling \n",
    "python /workspace/projects/001_scDiffusion/scripts/scDiffusion/classifier_sample.py --model_path \"/workspace/projects/001_scDiffusion/results/waddington/diffusion_model/WOT_diffusion_model/model080000.pt\" --classifier_path \"/workspace/projects/001_scDiffusion/results/waddington/classifier_model/model099999.pt\" --sample_dir \"/workspace/projects/001_scDiffusion/results/waddington/generated_latent_spaces/\" --ae_dir '/workspace/projects/001_scDiffusion/results/waddington/VAE_model/model_seed=0_step=49999.pt' --init_cell_path '/workspace/projects/001_scDiffusion/data/data_in/data/WOT/filted_data.h5ad' --num_gene 19423 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You have downladed GSM3195672_D6_Dox_C1_gene_bc_mat.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM3195672. At the bottom of the page, download the file in Supplementary file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then you can run the following command to get the umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICE=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "### CHANGE IN FUNCTION OF YOUR FILE SYSTEM ###\n",
    "vae_path = '/path/where/you/saved/the/VAE/model.pt'\n",
    "path_to_wot_data = '/path/where/you/saved/WOT/filted_data.h5ad'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('/workspace/projects/001_scDiffusion/scripts/scDiffusion/') ### CHANGE ACCORDING TO YOUR FILE SYSTEM\n",
    "from VAE.VAE_model import VAE\n",
    "import celltypist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_VAE():\n",
    "    autoencoder = VAE(\n",
    "        num_genes=19423,\n",
    "        device='cpu',\n",
    "        seed=0,\n",
    "        loss_ae='mse',\n",
    "        hidden_dim=128,\n",
    "        decoder_activation='ReLU',\n",
    "    )\n",
    "    autoencoder.load_state_dict(torch.load(vae_path, map_location=torch.device('cpu')))\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# load WOT dataset\n",
    "real_adata = sc.read_h5ad('path_to_wot_data')\n",
    "real_adata = real_adata[real_adata.obs.period.isin([\"D0\",\"D0.5\",\"D1\",\"D1.5\",\"D2\",\"D2.5\",\"D3\",\"D3.5\",\"D4\",\"D4.5\",\"D5\",\"D5.5\",\"D6\",\"D6.5\",\"D7\",\"D7.5\",\"D8\"])]\n",
    "real_adata = real_adata[::5]\n",
    "tmp_ = sc.read_10x_h5('/workspace/projects/001_scDiffusion/data/data_in/data/WOT/GSM3195672_D6_Dox_C1_gene_bc_mat.h5')\n",
    "real_adata.var_names_make_unique()\n",
    "gene_names = tmp_.var_names[real_adata.var_names.astype(np.int32)]\n",
    "sc.pp.normalize_total(real_adata, target_sum=1e4)\n",
    "sc.pp.log1p(real_adata)\n",
    "real_adata_period = real_adata.obs['period']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# load generated cells with different Gradient Interpolations\n",
    "gen_data = []\n",
    "cell_stage = []\n",
    "cell_dis = []\n",
    "\n",
    "for i in range(11):\n",
    "    npzfile=np.load(f'/workspace/projects/001_scDiffusion/results/waddington/generated_latent_spaces/{i}.npz',allow_pickle=True)\n",
    "    length = 500\n",
    "    gen_data.append(npzfile['cell_gen'][:int(length)])\n",
    "\n",
    "    cell_stage+=[f'gen {i}']*int(length)\n",
    "    cell_dis+=[float(i)]*int(length)\n",
    "\n",
    "gen_data = np.concatenate(gen_data,axis=0)\n",
    "number_of_gen_cells = gen_data.shape[0]\n",
    "\n",
    "\n",
    "autoencoder = load_VAE()\n",
    "gen_data = autoencoder(torch.tensor(gen_data).cpu(),return_decoded=True).cpu().detach().numpy()\n",
    "\n",
    "gen_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "adata = np.concatenate((real_adata.X,gen_data))\n",
    "adata = ad.AnnData(adata, dtype=np.float32)\n",
    "adata.obs['cell_gen_type'] = [f\"real_cell\" for i in range(real_adata.X.shape[0])]+[f\"gen_data\" for i in range(gen_data.shape[0])]\n",
    "adata.obs['cell_period'] = pd.Categorical(list(real_adata_period.values)+cell_stage)\n",
    "celldis = np.concatenate(([np.nan]*real_adata.X.shape[0], cell_dis)).astype(np.float32)\n",
    "adata.obs['cell_dis'] = celldis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) # why only highly variable genes?\n",
    "adata.raw = adata\n",
    "adata = adata[:, adata.var.highly_variable]\n",
    "\n",
    "sc.pp.scale(adata)\n",
    "sc.tl.pca(adata, svd_solver='arpack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20)\n",
    "sc.tl.umap(adata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "n_cell_periods = len(np.unique(adata.obs['cell_period']))  \n",
    "cmap = plt.get_cmap('viridis', n_cell_periods)  # Replace 'viridis' with your desired colormap  \n",
    "colors = [cmap(i) for i in range(cmap.N)]\n",
    "cell_type_color_map = dict(zip(np.unique(adata.obs['cell_period']), colors))\n",
    "cell_type_color_map['D3']='tab:red'\n",
    "cell_type_color_map['D3.5']='tab:orange'\n",
    "cell_type_color_map['D4']='tab:blue'\n",
    "cell_type_color_map['D4.5']='tab:green'\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "sc.pl.umap(adata=adata,color=\"cell_dis\", groups=list(np.unique(adata.obs['cell_dis'])), size=20, show=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
